[
  {
    "type": "transformers",
    "urlSuffix": "vicky7",
    "label": "vicky-7b",
    "model": "",
    "isEnabled": false,
    "isHidden": false,
    "deviceName": "cuda",
    "protocol": "http",
    "serverAddress": "127.0.0.1",
    "port": "64223",
    "requiresAccessToken": false,
    "maxTokens": 2060,
    "promptType": "vicuna1.1",
    "systemPrompt": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. ",
    "motd": "Please change model in the menu top-left - vicky7 is now decommissioned, vicky36 is in production",
    "motdColor": "",
    "motdHeading": "cuda",
    "motdHeadingColor": "#3bff3b"
  },
  {
    "type": "llamacpp",
    "urlSuffix": "mixtral8x7b",
    "label": "mixtral-8x7b (uncensored)",
    "model": "",
    "isEnabled": true,
    "isHidden": false,
    "deviceName": "cuda",
    "protocol": "http",
    "serverAddress": "127.0.0.1",
    "port": "64222",
    "requiresAccessToken": false,
    "maxTokens": 8096,
    "promptType": "mixtral8x7b",
    "systemPrompt": "",
    "motd": "My GPU is faulty and causing crashing issues with mixtral. RTX 3090s are expensive, so please consider donating to keep the uncensored AI alive here!",
    "motdColor": "",
    "motdHeading": "Hey guys!",
    "motdHeadingColor": "#32a852"
  },
  {
    "type": "openai",
    "urlSuffix": "groq",
    "label": "groq-mixtral8x7b (censored)",
    "model": "mixtral-8x7b-32768",
    "isEnabled": true,
    "isHidden": false,
    "deviceName": "cloud",
    "protocol": "https",
    "serverAddress": "api.groq.com/openai/v1/chat/completions",
    "port": "443",
    "requiresAccessToken": false,
    "maxTokens": 8096,
    "promptType": "gpt",
    "systemPrompt": "",
    "motd": "",
    "motdColor": "",
    "motdHeading": "",
    "motdHeadingColor": "#ff3b3b"
  },
  {
    "type": "llamacpp",
    "urlSuffix": "vicky36",
    "label": "vicky-36b",
    "model": "",
    "isEnabled": false,
    "isHidden": false,
    "deviceName": "cuda",
    "protocol": "http",
    "serverAddress": "127.0.0.1",
    "port": "64222",
    "requiresAccessToken": false,
    "maxTokens": 2060,
    "promptType": "airoboros",
    "systemPrompt": "",
    "motd": "",
    "motdColor": "",
    "motdHeading": "",
    "motdHeadingColor": "#ff3b3b"
  },
  {
    "type": "openai",
    "urlSuffix": "gpt-4",
    "label": "gpt-4",
    "model": "gpt-4",
    "isEnabled": true,
    "isHidden": false,
    "deviceName": "cloud",
    "protocol": "https",
    "serverAddress": "api.openai.com/v1/chat/completions",
    "port": "443",
    "requiresAccessToken": false,
    "maxTokens": 100000,
    "promptType": "gpt",
    "systemPrompt": "",
    "motd": "",
    "motdColor": "",
    "motdHeading": "",
    "motdHeadingColor": "#ff3b3b"
  },
  {
    "type": "openai",
    "urlSuffix": "gpt-4o",
    "label": "gpt-4o",
    "model": "gpt-4o",
    "isEnabled": true,
    "isHidden": false,
    "deviceName": "cloud",
    "protocol": "https",
    "serverAddress": "api.openai.com/v1/chat/completions",
    "port": "443",
    "requiresAccessToken": false,
    "maxTokens": 100000,
    "promptType": "gpt",
    "systemPrompt": "",
    "motd": "",
    "motdColor": "",
    "motdHeading": "",
    "motdHeadingColor": "#ff3b3b"
  },
  {
    "type": "openai",
    "urlSuffix": "gpt-4o-mini",
    "label": "gpt-4o-mini",
    "model": "gpt-4o-mini",
    "isEnabled": true,
    "isHidden": false,
    "deviceName": "cloud",
    "protocol": "https",
    "serverAddress": "api.openai.com/v1/chat/completions",
    "port": "443",
    "requiresAccessToken": false,
    "maxTokens": 100000,
    "promptType": "gpt",
    "systemPrompt": "",
    "motd": "",
    "motdColor": "",
    "motdHeading": "",
    "motdHeadingColor": "#ff3b3b"
  },
  {
    "type": "openai",
    "urlSuffix": "gpt-4-5",
    "label": "gpt-4.5-preview",
    "model": "gpt-4.5-preview",
    "isEnabled": true,
    "isHidden": false,
    "deviceName": "cloud",
    "protocol": "https",
    "serverAddress": "api.openai.com/v1/chat/completions",
    "port": "443",
    "requiresAccessToken": false,
    "maxTokens": 100000,
    "promptType": "gpt",
    "systemPrompt": "",
    "motd": "",
    "motdColor": "",
    "motdHeading": "",
    "motdHeadingColor": "#ff3b3b"
  },
  {
    "type": "openai",
    "urlSuffix": "gpt-o1",
    "label": "gpt-o1",
    "model": "o1",
    "isEnabled": true,
    "isHidden": false,
    "deviceName": "cloud",
    "protocol": "https",
    "serverAddress": "api.openai.com/v1/chat/completions",
    "port": "443",
    "requiresAccessToken": false,
    "maxTokens": 100000,
    "promptType": "gpt",
    "systemPrompt": "",
    "motd": "",
    "motdColor": "",
    "motdHeading": "",
    "motdHeadingColor": "#ff3b3b"
  },
  {
    "type": "openai",
    "urlSuffix": "gpt-o1-mini",
    "label": "gpt-o1-mini",
    "model": "o1-mini",
    "isEnabled": true,
    "isHidden": false,
    "deviceName": "cloud",
    "protocol": "https",
    "serverAddress": "api.openai.com/v1/chat/completions",
    "port": "443",
    "requiresAccessToken": false,
    "maxTokens": 100000,
    "promptType": "gpt",
    "systemPrompt": "",
    "motd": "",
    "motdColor": "",
    "motdHeading": "",
    "motdHeadingColor": "#ff3b3b"
  },
  {
    "type": "openai",
    "urlSuffix": "gpt-3.5-turbo",
    "label": "gpt-3.5-turbo",
    "model": "gpt-3.5-turbo",
    "isEnabled": true,
    "isHidden": false,
    "deviceName": "cloud",
    "protocol": "https",
    "serverAddress": "api.openai.com/v1/chat/completions",
    "port": "443",
    "requiresAccessToken": false,
    "maxTokens": 100000,
    "promptType": "gpt",
    "systemPrompt": "",
    "motd": "",
    "motdColor": "",
    "motdHeading": "",
    "motdHeadingColor": "#ff3b3b"
  },
  {
    "type": "openai",
    "urlSuffix": "gpt-o3-mini",
    "label": "gpt-o3-mini",
    "model": "o3-mini",
    "isEnabled": true,
    "isHidden": false,
    "deviceName": "cloud",
    "protocol": "https",
    "serverAddress": "api.openai.com/v1/chat/completions",
    "port": "443",
    "requiresAccessToken": false,
    "maxTokens": 100000,
    "promptType": "gpt",
    "systemPrompt": "",
    "motd": "",
    "motdColor": "",
    "motdHeading": "",
    "motdHeadingColor": "#ff3b3b"
  }
]
